{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ========== CELL 2: DATA PREPARATION  ==========\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Config\n",
        "DATA_DIR = \"/content/drive/MyDrive/COVID-CXR-Dataset\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Transforms\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "# Load data\n",
        "train_ds = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=train_tfms)\n",
        "val_ds = datasets.ImageFolder(f\"{DATA_DIR}/val\", transform=val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"âœ… Train: {len(train_ds)} images, Val: {len(val_ds)} images\")\n",
        "print(f\"âœ… Classes: {train_ds.classes}\")\n"
      ],
      "metadata": {
        "id": "rexHE-beKofQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHMae6xBwp7r"
      },
      "outputs": [],
      "source": [
        "# Install & Setup\n",
        "!pip install -q timm scikit-learn pandas matplotlib seaborn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os, random, time, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (classification_report, roc_auc_score,\n",
        "                           precision_recall_fscore_support, roc_curve, confusion_matrix)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"âœ… Environment ready\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Load best ViT-Tiny model\n",
        "best_model = timm.create_model('vit_tiny_patch16_224', pretrained=False, num_classes=2)\n",
        "best_model.load_state_dict(torch.load(\"best_vit_tiny_aug.pth\", map_location=device))\n",
        "best_model = best_model.to(device)\n",
        "best_model.eval()\n",
        "\n",
        "all_labels, all_preds, all_probs = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = best_model(images)\n",
        "        probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_probs.extend(probs)\n",
        "\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "\n",
        "# Classification Report\n",
        "print(\"=== ViT-Tiny Classification Report ===\")\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                          target_names=['Normal (0)', 'COVID (1)'],\n",
        "                          digits=4))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(\"\\n=== Confusion Matrix ===\")\n",
        "print(cm)\n",
        "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
        "\n",
        "# Key Metrics\n",
        "sensitivity = tp / (tp + fn + 1e-8)\n",
        "specificity = tn / (tn + fp + 1e-8)\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "print(f\"\\nAccuracy           : {accuracy*100:.2f}%\")\n",
        "print(f\"Sensitivity (COVID): {sensitivity*100:.2f}%\")\n",
        "print(f\"Specificity (Normal): {specificity*100:.2f}%\")\n",
        "print(f\"AUC                : {auc*100:.2f}%\")\n",
        "\n",
        "# Save results\n",
        "metrics = pd.DataFrame({\n",
        "    'model': ['ViT-Tiny'],\n",
        "    'accuracy': [accuracy],\n",
        "    'auc': [auc],\n",
        "    'sensitivity_covid': [sensitivity],\n",
        "    'specificity_normal': [specificity]\n",
        "})\n",
        "metrics.to_csv('vit_tiny_metrics.csv', index=False)\n",
        "print(\"\\nâœ… Results saved to vit_tiny_metrics.csv\")"
      ],
      "metadata": {
        "id": "l_TMaaaUsIxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"âœ… Device:\", device)\n",
        "\n",
        "# ResNet-18 model\n",
        "resnet = timm.create_model('resnet18', pretrained=True, num_classes=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(resnet.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    all_labels, all_probs = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    return running_loss / total, correct / total, auc, all_labels, all_probs\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "best_val_auc = -1.0  # Use AUC instead of accuracy\n",
        "patience = 5\n",
        "no_improve = 0\n",
        "\n",
        "print(\"ðŸš€ Starting ResNet-18 Training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc = train_one_epoch(resnet, train_loader, optimizer, criterion)\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_acc, val_auc, _, _ = evaluate(resnet, val_loader, criterion)\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1:2d}/{num_epochs}\")\n",
        "    print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc*100:.2f}%\")\n",
        "    print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc*100:.2f}%, AUC={val_auc:.4f} ({epoch_time:.1f}s)\")\n",
        "\n",
        "    # Early stopping based on AUC\n",
        "    if val_auc > best_val_auc + 1e-4:\n",
        "        best_val_auc = val_auc\n",
        "        torch.save({\n",
        "            'model_state_dict': resnet.state_dict(),\n",
        "            'epoch': epoch,\n",
        "            'val_auc': val_auc,\n",
        "            'val_acc': val_acc\n",
        "        }, \"best_resnet18_covid.pth\")\n",
        "        no_improve = 0\n",
        "        print(\"  âœ… Best model saved!\")\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve >= patience:\n",
        "            print(\"  ðŸ›‘ Early stopping\")\n",
        "            break\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Best ResNet-18 validation AUC: {best_val_auc*100:.2f}%\")\n",
        "print(\"âœ… Training completed!\")"
      ],
      "metadata": {
        "id": "zR3hpk3xtFMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"âœ… Ensemble Evaluation - Device:\", device)\n",
        "\n",
        "# Load best models\n",
        "vit = timm.create_model('vit_tiny_patch16_224', pretrained=False, num_classes=2).to(device)\n",
        "vit.load_state_dict(torch.load(\"best_vit_tiny_aug.pth\", map_location=device))\n",
        "vit.eval()\n",
        "\n",
        "resnet = timm.create_model('resnet18', pretrained=False, num_classes=2).to(device)\n",
        "resnet.load_state_dict(torch.load(\"best_resnet18_covid.pth\", map_location=device))\n",
        "resnet.eval()\n",
        "\n",
        "print(\"âœ… Models loaded successfully\")\n",
        "\n",
        "all_labels, all_vit_probs, all_res_probs, all_ens_probs, all_preds = [], [], [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Individual model predictions\n",
        "        out_vit = vit(images)\n",
        "        out_res = resnet(images)\n",
        "\n",
        "        prob_vit = torch.softmax(out_vit, dim=1)[:, 1].cpu().numpy()\n",
        "        prob_res = torch.softmax(out_res, dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "        # Ensemble: Simple probability averaging\n",
        "        prob_ens = (prob_vit + prob_res) / 2.0\n",
        "        pred_ens = (prob_ens >= 0.5).astype(int)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_vit_probs.extend(prob_vit)\n",
        "        all_res_probs.extend(prob_res)\n",
        "        all_ens_probs.extend(prob_ens)\n",
        "        all_preds.extend(pred_ens)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "all_ens_probs = np.array(all_ens_probs)\n",
        "\n",
        "print(\"=== CNNâ€“ViT Ensemble Results ===\")\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                          target_names=['Normal (0)', 'COVID (1)'],\n",
        "                          digits=4))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
        "\n",
        "# Key Metrics\n",
        "sensitivity = tp / (tp + fn + 1e-8)\n",
        "specificity = tn / (tn + fp + 1e-8)\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "auc = roc_auc_score(all_labels, all_ens_probs)\n",
        "\n",
        "print(f\"\\nðŸŽ¯ FINAL ENSEMBLE METRICS:\")\n",
        "print(f\"Accuracy           : {accuracy*100:.2f}%\")\n",
        "print(f\"Sensitivity (COVID): {sensitivity*100:.2f}%\")\n",
        "print(f\"Specificity (Normal): {specificity*100:.2f}%\")\n",
        "print(f\"AUC                : {auc*100:.2f}%\")\n",
        "\n",
        "# Save comprehensive results\n",
        "results = pd.DataFrame({\n",
        "    'y_true': all_labels,\n",
        "    'vit_prob': all_vit_probs,\n",
        "    'resnet_prob': all_res_probs,\n",
        "    'ensemble_prob': all_ens_probs,\n",
        "    'ensemble_pred': all_preds\n",
        "})\n",
        "results.to_csv('ensemble_predictions.csv', index=False)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    'model': ['CNN-ViT_Ensemble'],\n",
        "    'accuracy': [accuracy],\n",
        "    'auc': [auc],\n",
        "    'sensitivity_covid': [sensitivity],\n",
        "    'specificity_normal': [specificity]\n",
        "})\n",
        "summary.to_csv('ensemble_metrics.csv', index=False)\n",
        "\n",
        "print(\"\\nâœ… Results saved:\")\n",
        "print(\"  - ensemble_predictions.csv (detailed)\")\n",
        "print(\"  - ensemble_metrics.csv (summary)\")\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(all_labels, all_ens_probs)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, linewidth=2, label=f'Ensemble (AUC={auc:.3f})')\n",
        "plt.plot([0,1], [0,1], 'k--', alpha=0.5)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('CNNâ€“ViT Ensemble ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('ensemble_roc.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… ROC curve saved as ensemble_roc.png\")\n"
      ],
      "metadata": {
        "id": "EeZBkWIsuaTC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}